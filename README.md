保存了近期训练的一些GAN模型，其中：

- CGAN文件夹是之前训练的一个Conditional GAN模型，不过训练失败了（D失衡）。其实如果使用DCGAN后期的Discriminator的话理论上应该可以train出来，不过目前没有足够的计算资源和时间。
- DCGAN是用来生成二次元人脸的DCGAN模型。目前正在训练中，在1000轮左右时开始显现脸的轮廓

- pack中保存训练用的数据
  - selected中包括40\*40的1.8w张带标签的二次元人脸
  - tags.txt中每行为一个类别的标签，包括发色、瞳孔颜色和发长
  - filtered.txt中每行对应selected中一张人脸，从0开始计数

### 经验总结

训练的时候发现一些技巧：

- 每一轮迭代时，当D或是G的输出正确率达到$p_0$就停止训练了，因为这时候另一个模型的正确率已经很低了，如果一直训练下去可能会使得梯度变得很小，D和G就会失去平衡。我取的是$p_0=0.8$
- DCGAN中D的生成网络初始映射的channel一定要多，不要吝惜内存，不然很容易D就偏向只对realdata或是fakedata的输入判断，另一个正确率为0。大概是因为要保持realdata和fakedata的输入准确率都很高，所以尽量避免卷积时的信息损失吧
- G比D重要得多，我在服务器上跑有好多次都是数据忘记保存了，或是D或是G突然失效了，这种时候就要修改模型，一般如果G没有失效，只要保存G的参数，很快就能训练出新的D。并且DCGAN里面G的参数少得多，所以文件也方便保存
- 对于D，real和fake的训练最好分开，这样才好在D失衡的时候调整训练方向，比如如果在real上的准确率达到0.8，就可以先停止在realdata上训练
- 为了防止出现D强G弱的现象，在计算D的损失函数时，不直接使用$\{0,1\}$标签，而是加入随机噪声
- 大部分模型学习速率0.0002最佳
- G的输出可以用tanh规范化到$[-1,1]$
- D的网络中加入批规范化(BatchNormalize)效果非常好
- 在D中使用LeakyReLU

### DCGAN的训练过程

实际上训练尚未结束，不过近期可能没时间继续训练了，记一下当前的进度吧，目前一共跑了大概四个多小时。

- 刚开始的300轮非常快，大概十几分钟就跑完了
- 800轮时D失效，无论怎么训练都是在realdata的正确率为100%，在fakedata正确率为0。回退到700轮将$p_0$减小为$0.7$，重新训练D。
- 在900轮时D再次失效，出现D在fakedata正确率100%，在realdata正确率为0%，导致G梯度消失没办法训练。这次没有保存D，并且D已经开始不稳定，所以更改了D的结构，增加channel数，并且单独训练10个epoch($10个epoch\times 5个d\_epoch$)，G和D重新达到平衡。

### 训练结果

部分模型和中间改进的网络结构及G的输出见文件夹。目前1240轮的输出如下：

![](https://github.com/lengjiayi/GAN_Models/blob/master/DCGAN/1240epoch/Figure_1.png)